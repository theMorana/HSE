{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theMorana/HSE/blob/main/Hometask%20%236.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1: выгрузка файлов"
      ],
      "metadata": {
        "id": "aa2G_JERA7yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Зайдите в репозиторий датасетов для обучения диалоговых систем\n",
        "2. Найдите все файлы с расширением *.txt (их всего 5 в репозитории)\n",
        "3. Выгрузите каждый файл с помощью утилиты `wget`\n",
        "- Для этого откройте датасет в браузере, например, https://github.com/Phylliida/Dialogue-Datasets/blob/master/TwitterLowerAsciiCorpus.txt\n",
        "- Затем найдите кнопку `raw`, которая откроет вам файл \"как есть\" (как в блокноте!)\n",
        "- Скопируйте ссылку на файл (она выглядит так: https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt)\n",
        "- Воспользуйтесь `wget`\n",
        "---\n",
        "Как использовать `wget`:\n",
        "---"
      ],
      "metadata": {
        "id": "vrtdr5UF_TyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swBssiVj90wr",
        "outputId": "f95c9d5d-49e0-4c36-ba08-1cdfd980dcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-02 17:07:46--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "\rtwitter.txt           0%[                    ]       0  --.-KB/s               \rtwitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-12-02 17:07:46 (18.0 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь:\n",
        "- ! указывает на то, что это консольная утилита, а не код на python\n",
        "- после wget идет полный адрес ссылки для скачивания файла\n",
        "- после параметра `-O` указываем название файла, под которым мы хотим скачать файл"
      ],
      "metadata": {
        "id": "kekDrEGyAXUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y1EaoyncNK8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: повторите процедуру для остальных файлов (всего должно быть 5 файлов)"
      ],
      "metadata": {
        "id": "1FAveoWrAWm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Avengers_dialogue_dataset.txt -O avengers.txt\n",
        "!wget https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Black_Panter_dialogue_dataset.txt -O black_panter.txt\n",
        "!wget https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Spiderman_3_dialogue_dataset.txt -O spiderman.txt\n",
        "!wget https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Thor_dialogue_dataset.txt -O thor.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZiX_jqNL1l",
        "outputId": "d194c5cb-7cb6-4300-b261-2f78699325cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-02 17:07:48--  https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Avengers_dialogue_dataset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 55994 (55K) [text/plain]\n",
            "Saving to: ‘avengers.txt’\n",
            "\n",
            "avengers.txt        100%[===================>]  54.68K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-12-02 17:07:48 (6.30 MB/s) - ‘avengers.txt’ saved [55994/55994]\n",
            "\n",
            "--2025-12-02 17:07:48--  https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Black_Panter_dialogue_dataset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44047 (43K) [text/plain]\n",
            "Saving to: ‘black_panter.txt’\n",
            "\n",
            "black_panter.txt    100%[===================>]  43.01K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-12-02 17:07:48 (6.30 MB/s) - ‘black_panter.txt’ saved [44047/44047]\n",
            "\n",
            "--2025-12-02 17:07:49--  https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Spiderman_3_dialogue_dataset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62172 (61K) [text/plain]\n",
            "Saving to: ‘spiderman.txt’\n",
            "\n",
            "spiderman.txt       100%[===================>]  60.71K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-12-02 17:07:49 (8.19 MB/s) - ‘spiderman.txt’ saved [62172/62172]\n",
            "\n",
            "--2025-12-02 17:07:49--  https://raw.githubusercontent.com/theMorana/HSE/refs/heads/main/Homeworks/Hometask%20%235/Marvel%20dialogue%20datasets/Thor_dialogue_dataset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37943 (37K) [text/plain]\n",
            "Saving to: ‘thor.txt’\n",
            "\n",
            "thor.txt            100%[===================>]  37.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-02 17:07:49 (127 MB/s) - ‘thor.txt’ saved [37943/37943]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2: открываем файлы"
      ],
      "metadata": {
        "id": "JLaq0LFXBBI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изучите туториал по работе с файлами, который вы получили в чате. Каждый файл нужно теперь открыть, а его содержание - записать в переменную *любым удобным вам способом*\n",
        "\n",
        "Пример:"
      ],
      "metadata": {
        "id": "AjNtW5R1BI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "_uJqiGUpBFEV",
        "outputId": "b1525277-7047-4bc8-ea20-65a41e053091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text 2\n",
        "file = open('avengers.txt', 'r', encoding='utf-8')\n",
        "avengers_dataset = file.read()\n",
        "file.close()\n",
        "\n",
        "print(f\"Файл avengers.txt успешно загружен!\")\n",
        "print(f\"Размер файла: {len(avengers_dataset)} символов\")\n",
        "\n",
        "#text 3\n",
        "file = open('black_panter.txt', 'r', encoding='utf-8')\n",
        "black_panter_dataset = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл black_panter.txt успешно загружен!\")\n",
        "print(f\"Размер файла: {len(black_panter_dataset)} символов\")\n",
        "\n",
        "\n",
        "#text 4\n",
        "file = open('spiderman.txt', 'r', encoding='utf-8')\n",
        "spiderman_dataset = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл spiderman.txt успешно загружен!\")\n",
        "print(f\"Размер файла: {len(spiderman_dataset)} символов\")\n",
        "\n",
        "#text 5\n",
        "file = open('thor.txt', 'r', encoding='utf-8')\n",
        "thor_dataset = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл thor.txt успешно загружен!\")\n",
        "print(f\"Размер файла: {len(thor_dataset)} символов\")\n"
      ],
      "metadata": {
        "id": "yrYxdTj6BGv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575c10ed-9c21-435c-bf31-5c3b3245dbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл avengers.txt успешно загружен!\n",
            "Размер файла: 54238 символов\n",
            "Файл black_panter.txt успешно загружен!\n",
            "Размер файла: 42471 символов\n",
            "Файл spiderman.txt успешно загружен!\n",
            "Размер файла: 60446 символов\n",
            "Файл thor.txt успешно загружен!\n",
            "Размер файла: 36754 символов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3: первичный анализ"
      ],
      "metadata": {
        "id": "vSc5RUhgBu_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем статистику для каждого файла по образцу:"
      ],
      "metadata": {
        "id": "ui-vA_4wB76-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "lines = dataset_content.splitlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "total_lines = len(lines)\n",
        "\n",
        "for line in lines:\n",
        "    total_chars += len(line)\n",
        "    if len(line.strip()) > 0:\n",
        "        non_empty_lines += 1\n",
        "        words = line.split()  # разбиваем строку на слова\n",
        "        total_words += len(words)\n",
        "\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in lines:\n",
        "    line_lenght = len(line)\n",
        "    if line_lenght > max_line_length:\n",
        "        max_line_length = line_lenght\n",
        "    if line_lenght < min_line_length and line_lenght > 0:\n",
        "        min_line_length = line_lenght\n",
        "if min_line_length == float('inf'):\n",
        "    min_line_length = 0\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XliSd4K4Byym",
        "outputId": "74a243cc-d3fd-4d7d-a5cc-ae669c75834f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 577151\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4: чистка текста"
      ],
      "metadata": {
        "id": "aptZI3yhEOlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = []\n",
        "all_cleaned_words = []\n",
        "\n",
        "for line in lines:\n",
        "    # 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    line = line.strip()\n",
        "\n",
        "    if line:\n",
        "        # 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "        line = re.sub(r'[^a-zA-Zа-яё0-9\\s]', ' ', line)\n",
        "\n",
        "        # 3. Убираем лишние пробелы\n",
        "        line = re.sub(r'\\s+', ' ', line)\n",
        "\n",
        "        # 4. Приводим к нижнему регистру\n",
        "        line = line.lower()\n",
        "\n",
        "        # Сохраняем очищенную строку\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "        # 5. Собираем все слова после очистки в единый список\n",
        "        # не фиксируем слова короче 1 символа\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if len(word) > 1:\n",
        "                all_cleaned_words.append(word)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Очищенных строк: {len(cleaned_lines)}\")\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")\n",
        "print(\"Первые 5 очищенных строк:\")\n",
        "for i, line in enumerate(cleaned_lines[:5]):\n",
        "    print(f\"  {i+1}. {line}\")\n",
        "print(\"Первые 10 уникальных слов:\")\n",
        "unique_words = list(set(all_cleaned_words))[:10]\n",
        "for i, word in enumerate(unique_words):\n",
        "    print(f\"  {i+1}. {word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDEshS1DMo4",
        "outputId": "aa246152-1e57-4eb9-d902-0a45ad5ac736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Очищенных строк: 10514\n",
            "Пример очищенной строки: what s up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 104967\n",
            "Первые 5 очищенных строк:\n",
            "  1. what s up dadyo when did you get back on twitter haha\n",
            "  2. like 2 weeks ago and it s going as terribly as i remember but deg is still hilarious so it s ok\n",
            "  3. literally never about that account love it \n",
            "  4. answer me this fellow apple peoples how many times in the past year have you used the escape key \n",
            "  5. about 50 times today terminal vim user \n",
            "Первые 10 уникальных слов:\n",
            "  1. quick\n",
            "  2. haunt\n",
            "  3. silence\n",
            "  4. act\n",
            "  5. mejorrr\n",
            "  6. shady\n",
            "  7. jackson\n",
            "  8. emma\n",
            "  9. ppl\n",
            "  10. pantry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5: статистика"
      ],
      "metadata": {
        "id": "WvPQoLBzGvAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 1: получаем статистику распределений длин слов"
      ],
      "metadata": {
        "id": "Iirxb-yneJqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Исправленный код: создаем список длин слов и считаем символы\n",
        "for word in all_cleaned_words:\n",
        "    word_len = len(word)  # получаем длину текущего слова\n",
        "    if word_len >= 1:     # проверяем длину слова (всегда true, т.к. уже отфильтровано)\n",
        "        word_lengths.append(word_len)  # добавляем ДЛИНУ слова в список\n",
        "        total_chars += word_len        # считаем символы в слове (не +1!)\n",
        "\n",
        "total_words_after = len(all_cleaned_words)  # общее количество слов после очистки\n",
        "\n",
        "# Анализ длин слов: исправленный подсчет частот длин\n",
        "word_length_count = {}\n",
        "for length in word_lengths:  # итерируем по СПИСКУ ДЛИН, а не по словам!\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1  # увеличиваем счетчик\n",
        "    else:\n",
        "        word_length_count[length] = 1   # создаем новую запись\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words_after}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Z1tTq5DQFA",
        "outputId": "cc277df2-9cb0-44b2-9a94-272da604b128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 104967\n",
            "Символов после очистки: 438282\n",
            "Распределение длин слов:\n",
            "  2 букв: 20430 слов\n",
            "  3 букв: 25349 слов\n",
            "  4 букв: 25124 слов\n",
            "  5 букв: 12802 слов\n",
            "  6 букв: 7759 слов\n",
            "  7 букв: 6005 слов\n",
            "  8 букв: 3435 слов\n",
            "  9 букв: 2024 слов\n",
            "  10 букв: 1063 слов\n",
            "  11 букв: 491 слов\n",
            "  12 букв: 238 слов\n",
            "  13 букв: 118 слов\n",
            "  14 букв: 51 слов\n",
            "  15 букв: 26 слов\n",
            "  16 букв: 17 слов\n",
            "  17 букв: 10 слов\n",
            "  18 букв: 5 слов\n",
            "  19 букв: 5 слов\n",
            "  20 букв: 5 слов\n",
            "  21 букв: 1 слов\n",
            "  22 букв: 2 слов\n",
            "  23 букв: 2 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 1 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  98 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 2: частотность слов"
      ],
      "metadata": {
        "id": "gFZj9nmSeSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "\n",
        "\n",
        "\n",
        "for word in all_cleaned_words:  # итерируем по СПИСКУ ДЛИН, а не по словам!\n",
        "    if word in word_frequency:\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "        word_frequency[word] += 1\n",
        "# иначе\n",
        "    else:\n",
        "        word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words = set(all_cleaned_words)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12uZ3UlLDSJv",
        "outputId": "ec6b2258-439b-434f-af02-d8d05ef1850f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'the': 2928 раз\n",
            "  2. 'to': 2579 раз\n",
            "  3. 'you': 2564 раз\n",
            "  4. 'it': 2075 раз\n",
            "  5. 'and': 1668 раз\n",
            "  6. 'that': 1450 раз\n",
            "  7. 'my': 1201 раз\n",
            "  8. 'in': 1174 раз\n",
            "  9. 'is': 1096 раз\n",
            "  10. 'of': 1084 раз\n",
            "\n",
            "Всего уникальных слов: 10765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Код для обработки всех файлов (я постаралась прописать функцию, надеюсь, что получилось нормально)"
      ],
      "metadata": {
        "id": "0VpI9HE3Hqll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    print(f\"Файл {filename} успешно загружен!\")\n",
        "    print(f\"Размер файла: {len(content)} символов\")\n",
        "    return content\n",
        "\n",
        "def split_to_lines(text):\n",
        "    return text.splitlines()\n",
        "\n",
        "def statistics_lines(lines):\n",
        "    total_lines = len(lines)\n",
        "    total_words = 0\n",
        "    total_chars = 0\n",
        "    non_empty_lines = 0\n",
        "\n",
        "    for line in lines:\n",
        "        total_chars += len(line)\n",
        "        if len(line.strip()) > 0:\n",
        "            non_empty_lines += 1\n",
        "            total_words += len(line.split())\n",
        "\n",
        "    max_line_length = 0\n",
        "    min_line_length = float('inf')\n",
        "    for line in lines:\n",
        "        line_len = len(line)\n",
        "        if line_len > max_line_length:\n",
        "            max_line_length = line_len\n",
        "        if 0 < line_len < min_line_length:\n",
        "            min_line_length = line_len\n",
        "    if min_line_length == float('inf'):\n",
        "        min_line_length = 0\n",
        "\n",
        "    print(f\"Всего строк: {total_lines}\")\n",
        "    print(f\"Непустых строк: {non_empty_lines}\")\n",
        "    print(f\"Всего слов: {total_words}\")\n",
        "    print(f\"Всего символов: {total_chars}\")\n",
        "    print(f\"Макс. длина строки: {max_line_length}\")\n",
        "    print(f\"Мин. длина строки: {min_line_length}\")\n",
        "    return {\n",
        "        'total_lines': total_lines,\n",
        "        'non_empty_lines': non_empty_lines,\n",
        "        'total_words': total_words,\n",
        "        'total_chars': total_chars,\n",
        "        'max_line_length': max_line_length,\n",
        "        'min_line_length': min_line_length\n",
        "    }\n",
        "\n",
        "def clean_text(lines):\n",
        "    cleaned_lines = []\n",
        "    all_cleaned_words = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            line = re.sub(r'[^a-zA-Zа-яё0-9\\s]', ' ', line)\n",
        "            line = re.sub(r'\\s+', ' ', line)\n",
        "            line = line.lower()\n",
        "            cleaned_lines.append(line)\n",
        "            words = line.split()\n",
        "            for word in words:\n",
        "                if len(word) > 1:\n",
        "                    all_cleaned_words.append(word)\n",
        "\n",
        "    print(f\"Очищенных строк: {len(cleaned_lines)}\")\n",
        "    print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "    print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")\n",
        "    print(\"Первые 5 очищенных строк:\")\n",
        "    for i, line in enumerate(cleaned_lines[:5]):\n",
        "        print(f\"  {i+1}. {line}\")\n",
        "    print(\"Первые 10 уникальных слов:\")\n",
        "    unique_words_sample = list(set(all_cleaned_words))[:10]\n",
        "    for i, word in enumerate(unique_words_sample):\n",
        "        print(f\"  {i+1}. {word}\")\n",
        "\n",
        "    return cleaned_lines, all_cleaned_words\n",
        "\n",
        "def word_stats(all_cleaned_words):\n",
        "    total_words_after = len(all_cleaned_words)\n",
        "    total_chars = 0\n",
        "    word_lengths = []\n",
        "\n",
        "    for word in all_cleaned_words:\n",
        "        word_len = len(word)\n",
        "        word_lengths.append(word_len)\n",
        "        total_chars += word_len\n",
        "\n",
        "    word_length_count = {}\n",
        "    for length in word_lengths:\n",
        "        word_length_count[length] = word_length_count.get(length, 0) + 1\n",
        "\n",
        "    print(f\"Слов после очистки: {total_words_after}\")\n",
        "    print(f\"Символов после очистки: {total_chars}\")\n",
        "    print(\"Распределение длин слов:\")\n",
        "    for length in sorted(word_length_count.keys()):\n",
        "        print(f\"  {length} букв: {word_length_count[length]} слов\")\n",
        "\n",
        "    word_frequency = {}\n",
        "    for word in all_cleaned_words:\n",
        "        word_frequency[word] = word_frequency.get(word, 0) + 1\n",
        "\n",
        "    word_count_pairs = [(count, word) for word, count in word_frequency.items()]\n",
        "    word_count_pairs.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    print(\"Топ-10 самых частых слов:\")\n",
        "    for i, (count, word) in enumerate(word_count_pairs[:10]):\n",
        "        print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "    unique_words = set(all_cleaned_words)\n",
        "    print(f\"\\nВсего уникальных слов: {len(unique_words)}\")\n",
        "\n",
        "    return {\n",
        "        'total_words_after': total_words_after,\n",
        "        'total_chars': total_chars,\n",
        "        'word_length_count': word_length_count,\n",
        "        'word_frequency': word_frequency,\n",
        "        'unique_words': unique_words\n",
        "    }\n",
        "\n",
        "def analyze_file(filename):\n",
        "    content = read_file(filename)\n",
        "    lines = split_to_lines(content)\n",
        "    statistics_lines(lines)\n",
        "    cleaned_lines, all_words = clean_text(lines)\n",
        "    word_stats(all_words)\n",
        "\n",
        "# Пример вызова для 5 файлов:\n",
        "filenames = [\n",
        "    'twitter.txt',\n",
        "    'avengers.txt',\n",
        "    'thor.txt',\n",
        "    'black_panter.txt',\n",
        "    'spiderman.txt'\n",
        "]\n",
        "\n",
        "for fname in filenames:\n",
        "    print(f\"\\n=== Анализ файла: {fname} ===\")\n",
        "    analyze_file(fname)"
      ],
      "metadata": {
        "id": "58p4eiiZBi7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d691cb0a-5645-4666-d767-afcc7f46d661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Анализ файла: twitter.txt ===\n",
            "Файл twitter.txt успешно загружен!\n",
            "Размер файла: 593707 символов\n",
            "Всего строк: 16556\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 577151\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 1\n",
            "Очищенных строк: 10514\n",
            "Пример очищенной строки: what s up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 104967\n",
            "Первые 5 очищенных строк:\n",
            "  1. what s up dadyo when did you get back on twitter haha\n",
            "  2. like 2 weeks ago and it s going as terribly as i remember but deg is still hilarious so it s ok\n",
            "  3. literally never about that account love it \n",
            "  4. answer me this fellow apple peoples how many times in the past year have you used the escape key \n",
            "  5. about 50 times today terminal vim user \n",
            "Первые 10 уникальных слов:\n",
            "  1. quick\n",
            "  2. haunt\n",
            "  3. silence\n",
            "  4. act\n",
            "  5. mejorrr\n",
            "  6. shady\n",
            "  7. jackson\n",
            "  8. emma\n",
            "  9. ppl\n",
            "  10. pantry\n",
            "Слов после очистки: 104967\n",
            "Символов после очистки: 438282\n",
            "Распределение длин слов:\n",
            "  2 букв: 20430 слов\n",
            "  3 букв: 25349 слов\n",
            "  4 букв: 25124 слов\n",
            "  5 букв: 12802 слов\n",
            "  6 букв: 7759 слов\n",
            "  7 букв: 6005 слов\n",
            "  8 букв: 3435 слов\n",
            "  9 букв: 2024 слов\n",
            "  10 букв: 1063 слов\n",
            "  11 букв: 491 слов\n",
            "  12 букв: 238 слов\n",
            "  13 букв: 118 слов\n",
            "  14 букв: 51 слов\n",
            "  15 букв: 26 слов\n",
            "  16 букв: 17 слов\n",
            "  17 букв: 10 слов\n",
            "  18 букв: 5 слов\n",
            "  19 букв: 5 слов\n",
            "  20 букв: 5 слов\n",
            "  21 букв: 1 слов\n",
            "  22 букв: 2 слов\n",
            "  23 букв: 2 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 1 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  98 букв: 1 слов\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'the': 2928 раз\n",
            "  2. 'to': 2579 раз\n",
            "  3. 'you': 2564 раз\n",
            "  4. 'it': 2075 раз\n",
            "  5. 'and': 1668 раз\n",
            "  6. 'that': 1450 раз\n",
            "  7. 'my': 1201 раз\n",
            "  8. 'in': 1174 раз\n",
            "  9. 'is': 1096 раз\n",
            "  10. 'of': 1084 раз\n",
            "\n",
            "Всего уникальных слов: 10765\n",
            "\n",
            "=== Анализ файла: avengers.txt ===\n",
            "Файл avengers.txt успешно загружен!\n",
            "Размер файла: 54238 символов\n",
            "Всего строк: 1753\n",
            "Непустых строк: 1753\n",
            "Всего слов: 10182\n",
            "Всего символов: 52486\n",
            "Макс. длина строки: 71\n",
            "Мин. длина строки: 3\n",
            "Очищенных строк: 1753\n",
            "Пример очищенной строки: the tesseract has awakened ...\n",
            "Всего очищенных слов: 9651\n",
            "Первые 5 очищенных строк:\n",
            "  1. the tesseract has awakened \n",
            "  2. it is on a little world a human world \n",
            "  3. they would wield its power \n",
            "  4. but our ally knows its workings as they never will \n",
            "  5. he is ready to lead\n",
            "Первые 10 уникальных слов:\n",
            "  1. grid\n",
            "  2. bay\n",
            "  3. natural\n",
            "  4. others\n",
            "  5. meet\n",
            "  6. sometime\n",
            "  7. act\n",
            "  8. liars\n",
            "  9. barrel\n",
            "  10. junction\n",
            "Слов после очистки: 9651\n",
            "Символов после очистки: 39727\n",
            "Распределение длин слов:\n",
            "  2 букв: 2002 слов\n",
            "  3 букв: 2379 слов\n",
            "  4 букв: 2266 слов\n",
            "  5 букв: 1121 слов\n",
            "  6 букв: 698 слов\n",
            "  7 букв: 464 слов\n",
            "  8 букв: 337 слов\n",
            "  9 букв: 204 слов\n",
            "  10 букв: 97 слов\n",
            "  11 букв: 44 слов\n",
            "  12 букв: 22 слов\n",
            "  13 букв: 10 слов\n",
            "  14 букв: 5 слов\n",
            "  15 букв: 1 слов\n",
            "  16 букв: 1 слов\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'you': 438 раз\n",
            "  2. 'the': 383 раз\n",
            "  3. 'to': 286 раз\n",
            "  4. 'it': 186 раз\n",
            "  5. 'we': 165 раз\n",
            "  6. 'that': 146 раз\n",
            "  7. 'is': 138 раз\n",
            "  8. 'of': 128 раз\n",
            "  9. 'and': 123 раз\n",
            "  10. 'he': 113 раз\n",
            "\n",
            "Всего уникальных слов: 1931\n",
            "\n",
            "=== Анализ файла: thor.txt ===\n",
            "Файл thor.txt успешно загружен!\n",
            "Размер файла: 36754 символов\n",
            "Всего строк: 1190\n",
            "Непустых строк: 1189\n",
            "Всего слов: 6854\n",
            "Всего символов: 35565\n",
            "Макс. длина строки: 79\n",
            "Мин. длина строки: 3\n",
            "Очищенных строк: 1189\n",
            "Пример очищенной строки:  beeping ...\n",
            "Всего очищенных слов: 6493\n",
            "Первые 5 очищенных строк:\n",
            "  1.  beeping \n",
            "  2. wait for it \n",
            "  3.  can i turn on the radio no \n",
            "  4. erik jane you can t keep doing this \n",
            "  5. the last 17 occurrences have been predictable to the second \n",
            "Первые 10 уникальных слов:\n",
            "  1. peaceful\n",
            "  2. silence\n",
            "  3. others\n",
            "  4. act\n",
            "  5. alternative\n",
            "  6. alfheim\n",
            "  7. jackson\n",
            "  8. thinking\n",
            "  9. would\n",
            "  10. better\n",
            "Слов после очистки: 6493\n",
            "Символов после очистки: 26942\n",
            "Распределение длин слов:\n",
            "  2 букв: 1304 слов\n",
            "  3 букв: 1547 слов\n",
            "  4 букв: 1577 слов\n",
            "  5 букв: 736 слов\n",
            "  6 букв: 491 слов\n",
            "  7 букв: 364 слов\n",
            "  8 букв: 233 слов\n",
            "  9 букв: 138 слов\n",
            "  10 букв: 63 слов\n",
            "  11 букв: 22 слов\n",
            "  12 букв: 7 слов\n",
            "  13 букв: 6 слов\n",
            "  14 букв: 4 слов\n",
            "  15 букв: 1 слов\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'you': 324 раз\n",
            "  2. 'the': 205 раз\n",
            "  3. 'to': 182 раз\n",
            "  4. 'it': 124 раз\n",
            "  5. 'of': 113 раз\n",
            "  6. 'and': 103 раз\n",
            "  7. 'we': 86 раз\n",
            "  8. 'this': 78 раз\n",
            "  9. 'what': 76 раз\n",
            "  10. 'he': 74 раз\n",
            "\n",
            "Всего уникальных слов: 1361\n",
            "\n",
            "=== Анализ файла: black_panter.txt ===\n",
            "Файл black_panter.txt успешно загружен!\n",
            "Размер файла: 42471 символов\n",
            "Всего строк: 1574\n",
            "Непустых строк: 1574\n",
            "Всего слов: 7958\n",
            "Всего символов: 40898\n",
            "Макс. длина строки: 60\n",
            "Мин. длина строки: 3\n",
            "Очищенных строк: 1574\n",
            "Пример очищенной строки: baba ...\n",
            "Всего очищенных слов: 7584\n",
            "Первые 5 очищенных строк:\n",
            "  1. baba \n",
            "  2. yes my son \n",
            "  3. tell me a story \n",
            "  4. which one \n",
            "  5. the story of home \n",
            "Первые 10 уникальных слов:\n",
            "  1. quick\n",
            "  2. graduated\n",
            "  3. grid\n",
            "  4. silence\n",
            "  5. others\n",
            "  6. baku\n",
            "  7. kong\n",
            "  8. fix\n",
            "  9. trust\n",
            "  10. un\n",
            "Слов после очистки: 7584\n",
            "Символов после очистки: 31062\n",
            "Распределение длин слов:\n",
            "  2 букв: 1534 слов\n",
            "  3 букв: 1882 слов\n",
            "  4 букв: 1809 слов\n",
            "  5 букв: 916 слов\n",
            "  6 букв: 531 слов\n",
            "  7 букв: 427 слов\n",
            "  8 букв: 196 слов\n",
            "  9 букв: 186 слов\n",
            "  10 букв: 53 слов\n",
            "  11 букв: 30 слов\n",
            "  12 букв: 9 слов\n",
            "  13 букв: 7 слов\n",
            "  14 букв: 4 слов\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'you': 318 раз\n",
            "  2. 'the': 288 раз\n",
            "  3. 'to': 209 раз\n",
            "  4. 'it': 145 раз\n",
            "  5. 'of': 116 раз\n",
            "  6. 'is': 107 раз\n",
            "  7. 'and': 102 раз\n",
            "  8. 'we': 100 раз\n",
            "  9. 'what': 87 раз\n",
            "  10. 'your': 82 раз\n",
            "\n",
            "Всего уникальных слов: 1464\n",
            "\n",
            "=== Анализ файла: spiderman.txt ===\n",
            "Файл spiderman.txt успешно загружен!\n",
            "Размер файла: 60446 символов\n",
            "Всего строк: 1725\n",
            "Непустых строк: 1725\n",
            "Всего слов: 11270\n",
            "Всего символов: 58722\n",
            "Макс. длина строки: 82\n",
            "Мин. длина строки: 2\n",
            "Очищенных строк: 1725\n",
            "Пример очищенной строки: nick this was a tragedy but it s not why we re here ...\n",
            "Всего очищенных слов: 10810\n",
            "Первые 5 очищенных строк:\n",
            "  1. nick this was a tragedy but it s not why we re here \n",
            "  2. what are we fighting the weather now \n",
            "  3. locals say the cyclone had a face \n",
            "  4. people see things when they re under stress \n",
            "  5. that does not mean that this is the start to some other big world ending\n",
            "Первые 10 уникальных слов:\n",
            "  1. quick\n",
            "  2. peaceful\n",
            "  3. meet\n",
            "  4. shady\n",
            "  5. website\n",
            "  6. thinking\n",
            "  7. avengers\n",
            "  8. trust\n",
            "  9. headed\n",
            "  10. would\n",
            "Слов после очистки: 10810\n",
            "Символов после очистки: 43875\n",
            "Распределение длин слов:\n",
            "  2 букв: 2237 слов\n",
            "  3 букв: 2551 слов\n",
            "  4 букв: 2778 слов\n",
            "  5 букв: 1307 слов\n",
            "  6 букв: 757 слов\n",
            "  7 букв: 535 слов\n",
            "  8 букв: 297 слов\n",
            "  9 букв: 179 слов\n",
            "  10 букв: 98 слов\n",
            "  11 букв: 33 слов\n",
            "  12 букв: 22 слов\n",
            "  13 букв: 10 слов\n",
            "  14 букв: 3 слов\n",
            "  15 букв: 1 слов\n",
            "  16 букв: 1 слов\n",
            "  17 букв: 1 слов\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'you': 468 раз\n",
            "  2. 'the': 352 раз\n",
            "  3. 'it': 254 раз\n",
            "  4. 'to': 253 раз\n",
            "  5. 'that': 182 раз\n",
            "  6. 'and': 165 раз\n",
            "  7. 'what': 128 раз\n",
            "  8. 'yeah': 127 раз\n",
            "  9. 'is': 119 раз\n",
            "  10. 'we': 118 раз\n",
            "\n",
            "Всего уникальных слов: 1726\n"
          ]
        }
      ]
    }
  ]
}